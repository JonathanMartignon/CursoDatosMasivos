{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copia de lsh.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNnog2Mrm0sgdpVnbM34OV5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blancavazquez/CursoDatosMasivos/blob/master/notebooks/3e_lsh.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdUGGucRbHND",
        "colab_type": "text"
      },
      "source": [
        "# Búsqueda del vecino más cercano aproximado mediante funciones _hash_ sensibles a la localidad\n",
        "En esta libreta se realiza un buscador del vecino más cercano aproximado usando funciones _hash_ sensibles a la localidad (LSH). Especificamente, se define la familia LSH basada  en distribuciones $p$-estables para distancias $\\ell_1$ y $\\ell_2$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jp0vDo8kmXQ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import struct\n",
        "import os \n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.feature import hog\n",
        "from skimage import data, exposure\n",
        "from skimage import io, transform"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3Wvgq06cYGm",
        "colab_type": "text"
      },
      "source": [
        "Para evaluar el buscador vamos usar el conjunto de vectores SIFT [ANN_SIFT10K](http://corpus-texmex.irisa.fr/) del grupo TEXMEX, el cual descargamos y extraemos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wc2odYXEjxut",
        "colab_type": "code",
        "outputId": "2ec727e6-b7de-411a-a52a-566d20f3f794",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!wget -q ftp://ftp.irisa.fr/local/texmex/corpus/siftsmall.tar.gz\n",
        "!tar xvzf siftsmall.tar.gz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "siftsmall/\n",
            "siftsmall/siftsmall_base.fvecs\n",
            "siftsmall/siftsmall_groundtruth.ivecs\n",
            "siftsmall/siftsmall_learn.fvecs\n",
            "siftsmall/siftsmall_query.fvecs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcCrqcSsdPq9",
        "colab_type": "text"
      },
      "source": [
        "Definimos una función para leer los vectores de un archivo `.fvecs`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A21yFipGn27r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import struct\n",
        "import os \n",
        "\n",
        "def lee_fvecs(ruta):\n",
        "  with open(ruta, 'rb') as f:\n",
        "    d = struct.unpack('i', f.read(4))[0]\n",
        "    n = f.seek(0, os.SEEK_END) // (4 + 4 * d)\n",
        "    f.seek(0)\n",
        "    vecs = np.zeros((n, d))\n",
        "    for i in range(n):\n",
        "      f.read(4)\n",
        "      vecs[i] = struct.unpack('f' * d, f.read(d * 4))\n",
        "  \n",
        "  return vecs "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idVajqxIdYhc",
        "colab_type": "text"
      },
      "source": [
        "Leemos el conjunto de vectores base y consulta."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dVRDdDsG8ua",
        "colab_type": "code",
        "outputId": "1b1f2d51-817a-4b97-8a20-1fcd5f66c8e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "base = lee_fvecs('siftsmall/siftsmall_base.fvecs')\n",
        "consultas = lee_fvecs('siftsmall/siftsmall_query.fvecs')\n",
        "\n",
        "print('Base: {0} Consultas: {1}'.format(base.shape, consultas.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Base: (10000, 128) Consultas: (100, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMp9OQTJddXL",
        "colab_type": "text"
      },
      "source": [
        "Definimos una función para leer los vectores más cercanos reales (_groundtruth_) de un archivo `.ivecs`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtJ_pLDXHy1L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lee_ivecs(ruta):\n",
        "  with open(ruta, 'rb') as f:\n",
        "    d = struct.unpack('i', f.read(4))[0]\n",
        "    n = f.seek(0, os.SEEK_END) // (4 + 4 * d)\n",
        "    f.seek(0)\n",
        "    vecs = np.zeros((n, d), dtype=np.int)\n",
        "    for i in range(n):\n",
        "      f.read(4)\n",
        "      vecs[i] = struct.unpack('i' * d, f.read(d * 4))\n",
        "  \n",
        "  return vecs "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URIfS7yYdwji",
        "colab_type": "text"
      },
      "source": [
        "Leemos estos vectores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2njOGnqI1N1",
        "colab_type": "code",
        "outputId": "ba9c01a2-736a-400f-f3f7-52f58dac8e9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "gt = lee_ivecs('siftsmall/siftsmall_groundtruth.ivecs')\n",
        "print('Groundtruth: {0}'.format(gt.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Groundtruth: (100, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4RtFE5QdzYm",
        "colab_type": "text"
      },
      "source": [
        "Definimos nuestra clase para tabla _hash_ basado en distribuciones $s$-estables para distancias $\\ell_1$ y $\\ell_2$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jc1K6B1MQSNk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TablaLpLSH:\n",
        "  def __init__(self, n_cubetas, t_tupla, dim, width, norma = 'l2'):\n",
        "    self.n_cubetas = n_cubetas\n",
        "    self.tabla = [[] for i in range(n_cubetas)]\n",
        "    self.t_tupla = t_tupla\n",
        "    self.dim = dim\n",
        "    self.w = width\n",
        "\n",
        "    if norma == 'l2':\n",
        "      self.Amat = np.random.standard_normal((t_tupla, dim))\n",
        "    elif norma == 'l1':\n",
        "      self.Amat = np.random.standard_cauchy((t_tupla, dim))\n",
        "\n",
        "    self.bvec = np.random.uniform(low=0, high=self.w, size=t_tupla)\n",
        "    self.a = np.random.randint(0, np.iinfo(np.int32).max, size=self.t_tupla)\n",
        "    self.b = np.random.randint(0, np.iinfo(np.int32).max, size=self.t_tupla)\n",
        "    self.primo = 4294967291\n",
        "\n",
        "  def __repr__(self):\n",
        "    contenido = ['%d::%s' % (i, self.tabla[i]) for i in range(self.n_cubetas)]\n",
        "    return \"<TablaHash :%s >\" % ('\\n'.join(contenido))\n",
        "\n",
        "  def __str__(self):\n",
        "    contenido = ['%d::%s' % (i, self.tabla[i]) for i in range(self.n_cubetas) if self.tabla[i]]\n",
        "    return '\\n'.join(contenido)\n",
        "\n",
        "  def sl(self, x, i):\n",
        "    return (self.h(x) + i) % self.n_cubetas\n",
        "\n",
        "  def h(self, x):\n",
        "    return x % self.primo\n",
        "\n",
        "  def lphash(self, x):\n",
        "    prod = np.floor((self.Amat @ x.T + self.bvec) / self.w).astype(int)\n",
        "    return np.sum(self.a * prod, dtype=np.ulonglong), np.sum(self.b * prod, dtype=np.ulonglong)\n",
        "     \n",
        "  def insertar(self, x, ident):\n",
        "    lph, v2 = self.lphash(x)\n",
        "\n",
        "    llena = True\n",
        "    for i in range(self.n_cubetas):\n",
        "      cubeta = int(self.sl(v2, i))\n",
        "      if not self.tabla[cubeta]:\n",
        "        self.tabla[cubeta].append(lph)\n",
        "        self.tabla[cubeta].append([ident])\n",
        "        llena = False\n",
        "        break\n",
        "      elif self.tabla[cubeta][0] == lph:\n",
        "        self.tabla[cubeta][1].append(ident)\n",
        "        llena = False\n",
        "        break\n",
        "\n",
        "    if llena:\n",
        "      print('¡Error, tabla llena!')\n",
        "\n",
        "  def buscar(self, x):\n",
        "    mh, v2 = self.lphash(x)\n",
        "\n",
        "    for i in range(self.n_cubetas):\n",
        "      cubeta = int(self.sl(v2, i))\n",
        "      if not self.tabla[cubeta]:\n",
        "        return []\n",
        "      elif self.tabla[cubeta][0] == mh:\n",
        "        return self.tabla[cubeta][1]\n",
        "        \n",
        "    return []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdEgt1NZd_J5",
        "colab_type": "text"
      },
      "source": [
        "Instanciamos las tablas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gah2U0HDjezy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_tablas = 100\n",
        "dim = base.shape[1]\n",
        "tablas = [TablaLpLSH(2**14, 2, dim, 60.0) for _ in range(n_tablas)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sq5d8JpseClV",
        "colab_type": "text"
      },
      "source": [
        "Insertamos los vectores en cada tabla."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-7H_zh8ji__",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i,x in enumerate(base):\n",
        "  for t in range(n_tablas):\n",
        "    tablas[t].insertar(x, i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXT__NpoeGnJ",
        "colab_type": "text"
      },
      "source": [
        "Realizamos la búsqueda de los vectores de consulta y recuperamos los vectores más similares del conjunto base."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muvQIHOcjmy2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vecs = []\n",
        "for i,q in enumerate(consultas):\n",
        "  dc = []\n",
        "  for t in range(n_tablas):\n",
        "      dc.extend(tablas[t].buscar(q))\n",
        "  vecs.append(set(dc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0lg4Em1eLLD",
        "colab_type": "text"
      },
      "source": [
        "Calculamos la distancia euclidiana entre cada vector de consulta y sus correspondientes vectores recuperados y los ordenamos por distancia."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZyA31aXjo-J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def distancia_euclidiana(x, y):   \n",
        "  return np.sqrt(np.sum((x - y)**2))\n",
        "\n",
        "def fuerza_bruta(ds, qs, fd):\n",
        "  medidas = np.zeros(ds.shape[0])\n",
        "  for i,x in enumerate(ds):\n",
        "    medidas[i] = fd(qs, x)\n",
        "\n",
        "  return np.sort(medidas), np.argsort(medidas)\n",
        "\n",
        "dists = []\n",
        "orden = []\n",
        "for i,q in enumerate(consultas):\n",
        "  ld = list(vecs[i])\n",
        "  if ld:\n",
        "    m,o = fuerza_bruta(base[ld], q, distancia_euclidiana)\n",
        "    dists.append(m)\n",
        "    orden.append([ld[e] for e in o])\n",
        "  else:\n",
        "    dists.append([])\n",
        "    orden.append([])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCJtOHB3ebuW",
        "colab_type": "text"
      },
      "source": [
        "Extraemos los vecinos más cercanos encontrados por LSH y los reales y los comparamos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24gZNDZLSpkN",
        "colab_type": "code",
        "outputId": "608a27d4-4b22-4834-c793-90ef5cf33846",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vmc_lsh = [o[0] if o else -1 for o in orden]\n",
        "vmc_real = [g[0] for g in gt]\n",
        "correcto = [vmc_lsh[i] == vmc_real[i] for i in range(len(vmc_lsh))]\n",
        "print('Promedio encontrados = {0}'.format(np.mean(correcto)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Promedio encontrados = 0.32\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}